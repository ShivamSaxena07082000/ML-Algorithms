{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import plotly.express as px\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Type</th>\n",
       "      <th>Beds</th>\n",
       "      <th>Baths</th>\n",
       "      <th>SquareFeet</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SACRAMENTO</td>\n",
       "      <td>Residential</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>836</td>\n",
       "      <td>138159.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SACRAMENTO</td>\n",
       "      <td>Residential</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1167</td>\n",
       "      <td>167541.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SACRAMENTO</td>\n",
       "      <td>Residential</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>796</td>\n",
       "      <td>119095.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SACRAMENTO</td>\n",
       "      <td>Residential</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>852</td>\n",
       "      <td>130904.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SACRAMENTO</td>\n",
       "      <td>Residential</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>797</td>\n",
       "      <td>120266.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>SACRAMENTO</td>\n",
       "      <td>Residential</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2280</td>\n",
       "      <td>308248.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>SACRAMENTO</td>\n",
       "      <td>Residential</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1477</td>\n",
       "      <td>212857.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>CITRUS HEIGHTS</td>\n",
       "      <td>Residential</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1216</td>\n",
       "      <td>181746.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>ELK GROVE</td>\n",
       "      <td>Residential</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1685</td>\n",
       "      <td>245385.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>EL DORADO HILLS</td>\n",
       "      <td>Residential</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1362</td>\n",
       "      <td>263355.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>814 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                City         Type  Beds  Baths  SquareFeet      Price\n",
       "0         SACRAMENTO  Residential     2      1         836  138159.85\n",
       "1         SACRAMENTO  Residential     3      1        1167  167541.46\n",
       "2         SACRAMENTO  Residential     2      1         796  119095.12\n",
       "3         SACRAMENTO  Residential     2      1         852  130904.95\n",
       "4         SACRAMENTO  Residential     2      1         797  120266.19\n",
       "..               ...          ...   ...    ...         ...        ...\n",
       "809       SACRAMENTO  Residential     4      3        2280  308248.47\n",
       "810       SACRAMENTO  Residential     3      2        1477  212857.63\n",
       "811   CITRUS HEIGHTS  Residential     3      2        1216  181746.98\n",
       "812        ELK GROVE  Residential     4      2        1685  245385.59\n",
       "813  EL DORADO HILLS  Residential     3      2        1362  263355.13\n",
       "\n",
       "[814 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/digipodium/Datasets/main/house_pricing.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df[['Beds','Baths','SquareFeet']]\n",
    "y=df['Price']\n",
    "xtrain,xtest,ytrain,ytest= train_test_split(x,y,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest\n",
      "Score: 71.78019506681817\n",
      "Mean Absolute Error: 15250.941631000855\n",
      "Mean Squared Error: 879151686.1558949\n"
     ]
    }
   ],
   "source": [
    "print(\"Random forest\")\n",
    "model1=RandomForestRegressor()\n",
    "model1.fit(xtrain,ytrain)\n",
    "print(\"Score:\",model1.score(xtest,ytest)*100)\n",
    "pred=model1.predict(x)\n",
    "print(\"Mean Absolute Error:\",mean_absolute_error(y,pred))\n",
    "print(\"Mean Squared Error:\",mean_squared_error(y,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "[0.80330219 0.71148733 0.67366283 0.51513916 0.63377049] Average: 0.6674724001469793\n"
     ]
    }
   ],
   "source": [
    "tree_score=cross_val_score(model1,x,y)\n",
    "print(\"Random Forest\")\n",
    "print(tree_score,\"Average:\",tree_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#we are going to create a dictionary with all parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'squared_error'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmin_impurity_decrease\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbootstrap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0moob_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mwarm_start\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mccp_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmax_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "A random forest regressor.\n",
      "\n",
      "A random forest is a meta estimator that fits a number of classifying\n",
      "decision trees on various sub-samples of the dataset and uses averaging\n",
      "to improve the predictive accuracy and control over-fitting.\n",
      "The sub-sample size is controlled with the `max_samples` parameter if\n",
      "`bootstrap=True` (default), otherwise the whole dataset is used to build\n",
      "each tree.\n",
      "\n",
      "Read more in the :ref:`User Guide <forest>`.\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "n_estimators : int, default=100\n",
      "    The number of trees in the forest.\n",
      "\n",
      "    .. versionchanged:: 0.22\n",
      "       The default value of ``n_estimators`` changed from 10 to 100\n",
      "       in 0.22.\n",
      "\n",
      "criterion : {\"squared_error\", \"absolute_error\", \"poisson\"},             default=\"squared_error\"\n",
      "    The function to measure the quality of a split. Supported criteria\n",
      "    are \"squared_error\" for the mean squared error, which is equal to\n",
      "    variance reduction as feature selection criterion, \"absolute_error\"\n",
      "    for the mean absolute error, and \"poisson\" which uses reduction in\n",
      "    Poisson deviance to find splits.\n",
      "    Training using \"absolute_error\" is significantly slower\n",
      "    than when using \"squared_error\".\n",
      "\n",
      "    .. versionadded:: 0.18\n",
      "       Mean Absolute Error (MAE) criterion.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "       Poisson criterion.\n",
      "\n",
      "    .. deprecated:: 1.0\n",
      "        Criterion \"mse\" was deprecated in v1.0 and will be removed in\n",
      "        version 1.2. Use `criterion=\"squared_error\"` which is equivalent.\n",
      "\n",
      "    .. deprecated:: 1.0\n",
      "        Criterion \"mae\" was deprecated in v1.0 and will be removed in\n",
      "        version 1.2. Use `criterion=\"absolute_error\"` which is equivalent.\n",
      "\n",
      "max_depth : int, default=None\n",
      "    The maximum depth of the tree. If None, then nodes are expanded until\n",
      "    all leaves are pure or until all leaves contain less than\n",
      "    min_samples_split samples.\n",
      "\n",
      "min_samples_split : int or float, default=2\n",
      "    The minimum number of samples required to split an internal node:\n",
      "\n",
      "    - If int, then consider `min_samples_split` as the minimum number.\n",
      "    - If float, then `min_samples_split` is a fraction and\n",
      "      `ceil(min_samples_split * n_samples)` are the minimum\n",
      "      number of samples for each split.\n",
      "\n",
      "    .. versionchanged:: 0.18\n",
      "       Added float values for fractions.\n",
      "\n",
      "min_samples_leaf : int or float, default=1\n",
      "    The minimum number of samples required to be at a leaf node.\n",
      "    A split point at any depth will only be considered if it leaves at\n",
      "    least ``min_samples_leaf`` training samples in each of the left and\n",
      "    right branches.  This may have the effect of smoothing the model,\n",
      "    especially in regression.\n",
      "\n",
      "    - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "    - If float, then `min_samples_leaf` is a fraction and\n",
      "      `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "      number of samples for each node.\n",
      "\n",
      "    .. versionchanged:: 0.18\n",
      "       Added float values for fractions.\n",
      "\n",
      "min_weight_fraction_leaf : float, default=0.0\n",
      "    The minimum weighted fraction of the sum total of weights (of all\n",
      "    the input samples) required to be at a leaf node. Samples have\n",
      "    equal weight when sample_weight is not provided.\n",
      "\n",
      "max_features : {\"auto\", \"sqrt\", \"log2\"}, int or float, default=\"auto\"\n",
      "    The number of features to consider when looking for the best split:\n",
      "\n",
      "    - If int, then consider `max_features` features at each split.\n",
      "    - If float, then `max_features` is a fraction and\n",
      "      `round(max_features * n_features)` features are considered at each\n",
      "      split.\n",
      "    - If \"auto\", then `max_features=n_features`.\n",
      "    - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      "    - If \"log2\", then `max_features=log2(n_features)`.\n",
      "    - If None, then `max_features=n_features`.\n",
      "\n",
      "    Note: the search for a split does not stop until at least one\n",
      "    valid partition of the node samples is found, even if it requires to\n",
      "    effectively inspect more than ``max_features`` features.\n",
      "\n",
      "max_leaf_nodes : int, default=None\n",
      "    Grow trees with ``max_leaf_nodes`` in best-first fashion.\n",
      "    Best nodes are defined as relative reduction in impurity.\n",
      "    If None then unlimited number of leaf nodes.\n",
      "\n",
      "min_impurity_decrease : float, default=0.0\n",
      "    A node will be split if this split induces a decrease of the impurity\n",
      "    greater than or equal to this value.\n",
      "\n",
      "    The weighted impurity decrease equation is the following::\n",
      "\n",
      "        N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                            - N_t_L / N_t * left_impurity)\n",
      "\n",
      "    where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "    samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "    left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "    ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "    if ``sample_weight`` is passed.\n",
      "\n",
      "    .. versionadded:: 0.19\n",
      "\n",
      "bootstrap : bool, default=True\n",
      "    Whether bootstrap samples are used when building trees. If False, the\n",
      "    whole dataset is used to build each tree.\n",
      "\n",
      "oob_score : bool, default=False\n",
      "    Whether to use out-of-bag samples to estimate the generalization score.\n",
      "    Only available if bootstrap=True.\n",
      "\n",
      "n_jobs : int, default=None\n",
      "    The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,\n",
      "    :meth:`decision_path` and :meth:`apply` are all parallelized over the\n",
      "    trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`\n",
      "    context. ``-1`` means using all processors. See :term:`Glossary\n",
      "    <n_jobs>` for more details.\n",
      "\n",
      "random_state : int, RandomState instance or None, default=None\n",
      "    Controls both the randomness of the bootstrapping of the samples used\n",
      "    when building trees (if ``bootstrap=True``) and the sampling of the\n",
      "    features to consider when looking for the best split at each node\n",
      "    (if ``max_features < n_features``).\n",
      "    See :term:`Glossary <random_state>` for details.\n",
      "\n",
      "verbose : int, default=0\n",
      "    Controls the verbosity when fitting and predicting.\n",
      "\n",
      "warm_start : bool, default=False\n",
      "    When set to ``True``, reuse the solution of the previous call to fit\n",
      "    and add more estimators to the ensemble, otherwise, just fit a whole\n",
      "    new forest. See :term:`the Glossary <warm_start>`.\n",
      "\n",
      "ccp_alpha : non-negative float, default=0.0\n",
      "    Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      "    subtree with the largest cost complexity that is smaller than\n",
      "    ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      "    :ref:`minimal_cost_complexity_pruning` for details.\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "max_samples : int or float, default=None\n",
      "    If bootstrap is True, the number of samples to draw from X\n",
      "    to train each base estimator.\n",
      "\n",
      "    - If None (default), then draw `X.shape[0]` samples.\n",
      "    - If int, then draw `max_samples` samples.\n",
      "    - If float, then draw `max_samples * X.shape[0]` samples. Thus,\n",
      "      `max_samples` should be in the interval `(0.0, 1.0]`.\n",
      "\n",
      "    .. versionadded:: 0.22\n",
      "\n",
      "Attributes\n",
      "----------\n",
      "base_estimator_ : DecisionTreeRegressor\n",
      "    The child estimator template used to create the collection of fitted\n",
      "    sub-estimators.\n",
      "\n",
      "estimators_ : list of DecisionTreeRegressor\n",
      "    The collection of fitted sub-estimators.\n",
      "\n",
      "feature_importances_ : ndarray of shape (n_features,)\n",
      "    The impurity-based feature importances.\n",
      "    The higher, the more important the feature.\n",
      "    The importance of a feature is computed as the (normalized)\n",
      "    total reduction of the criterion brought by that feature.  It is also\n",
      "    known as the Gini importance.\n",
      "\n",
      "    Warning: impurity-based feature importances can be misleading for\n",
      "    high cardinality features (many unique values). See\n",
      "    :func:`sklearn.inspection.permutation_importance` as an alternative.\n",
      "\n",
      "n_features_ : int\n",
      "    The number of features when ``fit`` is performed.\n",
      "\n",
      "    .. deprecated:: 1.0\n",
      "        Attribute `n_features_` was deprecated in version 1.0 and will be\n",
      "        removed in 1.2. Use `n_features_in_` instead.\n",
      "\n",
      "n_features_in_ : int\n",
      "    Number of features seen during :term:`fit`.\n",
      "\n",
      "    .. versionadded:: 0.24\n",
      "\n",
      "feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      "    Names of features seen during :term:`fit`. Defined only when `X`\n",
      "    has feature names that are all strings.\n",
      "\n",
      "    .. versionadded:: 1.0\n",
      "\n",
      "n_outputs_ : int\n",
      "    The number of outputs when ``fit`` is performed.\n",
      "\n",
      "oob_score_ : float\n",
      "    Score of the training dataset obtained using an out-of-bag estimate.\n",
      "    This attribute exists only when ``oob_score`` is True.\n",
      "\n",
      "oob_prediction_ : ndarray of shape (n_samples,) or (n_samples, n_outputs)\n",
      "    Prediction computed with out-of-bag estimate on the training set.\n",
      "    This attribute exists only when ``oob_score`` is True.\n",
      "\n",
      "See Also\n",
      "--------\n",
      "sklearn.tree.DecisionTreeRegressor : A decision tree regressor.\n",
      "sklearn.ensemble.ExtraTreesRegressor : Ensemble of extremely randomized\n",
      "    tree regressors.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "The default values for the parameters controlling the size of the trees\n",
      "(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      "unpruned trees which can potentially be very large on some data sets. To\n",
      "reduce memory consumption, the complexity and size of the trees should be\n",
      "controlled by setting those parameter values.\n",
      "\n",
      "The features are always randomly permuted at each split. Therefore,\n",
      "the best found split may vary, even with the same training data,\n",
      "``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
      "of the criterion is identical for several splits enumerated during the\n",
      "search of the best split. To obtain a deterministic behaviour during\n",
      "fitting, ``random_state`` has to be fixed.\n",
      "\n",
      "The default value ``max_features=\"auto\"`` uses ``n_features``\n",
      "rather than ``n_features / 3``. The latter was originally suggested in\n",
      "[1], whereas the former was more recently justified empirically in [2].\n",
      "\n",
      "References\n",
      "----------\n",
      ".. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
      "\n",
      ".. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized\n",
      "       trees\", Machine Learning, 63(1), 3-42, 2006.\n",
      "\n",
      "Examples\n",
      "--------\n",
      ">>> from sklearn.ensemble import RandomForestRegressor\n",
      ">>> from sklearn.datasets import make_regression\n",
      ">>> X, y = make_regression(n_features=4, n_informative=2,\n",
      "...                        random_state=0, shuffle=False)\n",
      ">>> regr = RandomForestRegressor(max_depth=2, random_state=0)\n",
      ">>> regr.fit(X, y)\n",
      "RandomForestRegressor(...)\n",
      ">>> print(regr.predict([[0, 0, 0, 0]]))\n",
      "[-8.32987858]\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\dell\\appdata\\local\\programs\\python\\python310\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\n",
      "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
      "\u001b[1;31mSubclasses:\u001b[0m     \n"
     ]
    }
   ],
   "source": [
    "RandomForestRegressor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [100, 200, 300, 400, 500],\n",
       " 'criterion': ['squared_error', 'absolute_error', 'poisson'],\n",
       " 'max_depth': [5, 25, 45]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params={\n",
    "    'n_estimators':list(range(100,501,100)),\n",
    "    'criterion':['squared_error','absolute_error','poisson'],\n",
    "    'max_depth':list(range(5,50,20))\n",
    "}\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid=GridSearchCV(estimator=RandomForestRegressor(),param_grid=params,cv=3,n_jobs=-1,verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 45 candidates, totalling 135 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['squared_error', 'absolute_error',\n",
       "                                       'poisson'],\n",
       "                         'max_depth': [5, 25, 45],\n",
       "                         'n_estimators': [100, 200, 300, 400, 500]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gf=pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.597999</td>\n",
       "      <td>0.066716</td>\n",
       "      <td>0.045001</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 5,...</td>\n",
       "      <td>0.801477</td>\n",
       "      <td>0.768729</td>\n",
       "      <td>0.614334</td>\n",
       "      <td>0.728180</td>\n",
       "      <td>0.081604</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.199332</td>\n",
       "      <td>0.042459</td>\n",
       "      <td>0.088334</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 5,...</td>\n",
       "      <td>0.804023</td>\n",
       "      <td>0.768080</td>\n",
       "      <td>0.614281</td>\n",
       "      <td>0.728795</td>\n",
       "      <td>0.082292</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.003331</td>\n",
       "      <td>0.124196</td>\n",
       "      <td>0.128336</td>\n",
       "      <td>0.011815</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 5,...</td>\n",
       "      <td>0.804233</td>\n",
       "      <td>0.767697</td>\n",
       "      <td>0.619911</td>\n",
       "      <td>0.730613</td>\n",
       "      <td>0.079687</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.239998</td>\n",
       "      <td>0.061747</td>\n",
       "      <td>0.166669</td>\n",
       "      <td>0.030005</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 5,...</td>\n",
       "      <td>0.804081</td>\n",
       "      <td>0.766794</td>\n",
       "      <td>0.617244</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>0.080735</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.865997</td>\n",
       "      <td>0.114814</td>\n",
       "      <td>0.208668</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 5,...</td>\n",
       "      <td>0.801061</td>\n",
       "      <td>0.767800</td>\n",
       "      <td>0.612671</td>\n",
       "      <td>0.727177</td>\n",
       "      <td>0.082099</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.775999</td>\n",
       "      <td>0.047377</td>\n",
       "      <td>0.062001</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 25...</td>\n",
       "      <td>0.760389</td>\n",
       "      <td>0.754058</td>\n",
       "      <td>0.576831</td>\n",
       "      <td>0.697093</td>\n",
       "      <td>0.085077</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.657330</td>\n",
       "      <td>0.044011</td>\n",
       "      <td>0.139336</td>\n",
       "      <td>0.027011</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 25...</td>\n",
       "      <td>0.759118</td>\n",
       "      <td>0.753202</td>\n",
       "      <td>0.578857</td>\n",
       "      <td>0.697059</td>\n",
       "      <td>0.083616</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.323998</td>\n",
       "      <td>0.085515</td>\n",
       "      <td>0.151334</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>25</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 25...</td>\n",
       "      <td>0.752733</td>\n",
       "      <td>0.753976</td>\n",
       "      <td>0.579094</td>\n",
       "      <td>0.695268</td>\n",
       "      <td>0.082149</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.075998</td>\n",
       "      <td>0.073542</td>\n",
       "      <td>0.190999</td>\n",
       "      <td>0.013949</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>25</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 25...</td>\n",
       "      <td>0.753784</td>\n",
       "      <td>0.752243</td>\n",
       "      <td>0.581820</td>\n",
       "      <td>0.695949</td>\n",
       "      <td>0.080704</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.891667</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>0.084914</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>25</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 25...</td>\n",
       "      <td>0.758392</td>\n",
       "      <td>0.755369</td>\n",
       "      <td>0.578589</td>\n",
       "      <td>0.697450</td>\n",
       "      <td>0.084057</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.723665</td>\n",
       "      <td>0.093902</td>\n",
       "      <td>0.063669</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 45...</td>\n",
       "      <td>0.751193</td>\n",
       "      <td>0.752092</td>\n",
       "      <td>0.580875</td>\n",
       "      <td>0.694720</td>\n",
       "      <td>0.080502</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.403996</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.132004</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>45</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 45...</td>\n",
       "      <td>0.750571</td>\n",
       "      <td>0.755123</td>\n",
       "      <td>0.579620</td>\n",
       "      <td>0.695105</td>\n",
       "      <td>0.081681</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.347330</td>\n",
       "      <td>0.094462</td>\n",
       "      <td>0.142334</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>45</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 45...</td>\n",
       "      <td>0.750861</td>\n",
       "      <td>0.753541</td>\n",
       "      <td>0.578325</td>\n",
       "      <td>0.694242</td>\n",
       "      <td>0.081973</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.004330</td>\n",
       "      <td>0.058368</td>\n",
       "      <td>0.242001</td>\n",
       "      <td>0.033534</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>45</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 45...</td>\n",
       "      <td>0.753126</td>\n",
       "      <td>0.755528</td>\n",
       "      <td>0.573438</td>\n",
       "      <td>0.694030</td>\n",
       "      <td>0.085278</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.672999</td>\n",
       "      <td>0.078259</td>\n",
       "      <td>0.286002</td>\n",
       "      <td>0.056786</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>45</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 45...</td>\n",
       "      <td>0.748951</td>\n",
       "      <td>0.753111</td>\n",
       "      <td>0.582351</td>\n",
       "      <td>0.694804</td>\n",
       "      <td>0.079535</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.589333</td>\n",
       "      <td>0.107690</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 5...</td>\n",
       "      <td>0.823251</td>\n",
       "      <td>0.767422</td>\n",
       "      <td>0.612055</td>\n",
       "      <td>0.734243</td>\n",
       "      <td>0.089356</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.120330</td>\n",
       "      <td>0.086170</td>\n",
       "      <td>0.082666</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 5...</td>\n",
       "      <td>0.824188</td>\n",
       "      <td>0.767052</td>\n",
       "      <td>0.614568</td>\n",
       "      <td>0.735269</td>\n",
       "      <td>0.088479</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.596330</td>\n",
       "      <td>0.055259</td>\n",
       "      <td>0.111336</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 5...</td>\n",
       "      <td>0.823810</td>\n",
       "      <td>0.766413</td>\n",
       "      <td>0.611563</td>\n",
       "      <td>0.733929</td>\n",
       "      <td>0.089643</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.189996</td>\n",
       "      <td>0.079717</td>\n",
       "      <td>0.160666</td>\n",
       "      <td>0.009743</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 5...</td>\n",
       "      <td>0.824286</td>\n",
       "      <td>0.767629</td>\n",
       "      <td>0.615251</td>\n",
       "      <td>0.735722</td>\n",
       "      <td>0.088270</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.545000</td>\n",
       "      <td>0.135477</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.019593</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 5...</td>\n",
       "      <td>0.824991</td>\n",
       "      <td>0.767756</td>\n",
       "      <td>0.615117</td>\n",
       "      <td>0.735955</td>\n",
       "      <td>0.088583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.222995</td>\n",
       "      <td>0.101418</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.004544</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 2...</td>\n",
       "      <td>0.764010</td>\n",
       "      <td>0.758525</td>\n",
       "      <td>0.581797</td>\n",
       "      <td>0.701444</td>\n",
       "      <td>0.084632</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.370332</td>\n",
       "      <td>0.129208</td>\n",
       "      <td>0.100334</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 2...</td>\n",
       "      <td>0.771178</td>\n",
       "      <td>0.758695</td>\n",
       "      <td>0.578657</td>\n",
       "      <td>0.702844</td>\n",
       "      <td>0.087961</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.718998</td>\n",
       "      <td>1.376534</td>\n",
       "      <td>0.380668</td>\n",
       "      <td>0.095228</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>25</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 2...</td>\n",
       "      <td>0.763317</td>\n",
       "      <td>0.760079</td>\n",
       "      <td>0.572470</td>\n",
       "      <td>0.698622</td>\n",
       "      <td>0.089213</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.036998</td>\n",
       "      <td>0.777633</td>\n",
       "      <td>0.206668</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>25</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 2...</td>\n",
       "      <td>0.767483</td>\n",
       "      <td>0.757604</td>\n",
       "      <td>0.578968</td>\n",
       "      <td>0.701352</td>\n",
       "      <td>0.086632</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11.498999</td>\n",
       "      <td>0.798871</td>\n",
       "      <td>0.325002</td>\n",
       "      <td>0.075978</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>25</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 2...</td>\n",
       "      <td>0.768633</td>\n",
       "      <td>0.758758</td>\n",
       "      <td>0.579286</td>\n",
       "      <td>0.702226</td>\n",
       "      <td>0.087025</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.578665</td>\n",
       "      <td>0.247992</td>\n",
       "      <td>0.059001</td>\n",
       "      <td>0.011861</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 4...</td>\n",
       "      <td>0.771107</td>\n",
       "      <td>0.757026</td>\n",
       "      <td>0.581916</td>\n",
       "      <td>0.703350</td>\n",
       "      <td>0.086059</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.349664</td>\n",
       "      <td>0.333029</td>\n",
       "      <td>0.184339</td>\n",
       "      <td>0.008657</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>45</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 4...</td>\n",
       "      <td>0.767592</td>\n",
       "      <td>0.759651</td>\n",
       "      <td>0.575471</td>\n",
       "      <td>0.700905</td>\n",
       "      <td>0.088754</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11.814331</td>\n",
       "      <td>2.342956</td>\n",
       "      <td>0.510667</td>\n",
       "      <td>0.263015</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>45</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 4...</td>\n",
       "      <td>0.764764</td>\n",
       "      <td>0.760079</td>\n",
       "      <td>0.575481</td>\n",
       "      <td>0.700108</td>\n",
       "      <td>0.088145</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>24.536663</td>\n",
       "      <td>0.166643</td>\n",
       "      <td>0.713334</td>\n",
       "      <td>0.084307</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>45</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 4...</td>\n",
       "      <td>0.767133</td>\n",
       "      <td>0.759372</td>\n",
       "      <td>0.571456</td>\n",
       "      <td>0.699320</td>\n",
       "      <td>0.090469</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18.893997</td>\n",
       "      <td>3.770183</td>\n",
       "      <td>0.264002</td>\n",
       "      <td>0.024750</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>45</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 4...</td>\n",
       "      <td>0.762796</td>\n",
       "      <td>0.759418</td>\n",
       "      <td>0.577069</td>\n",
       "      <td>0.699761</td>\n",
       "      <td>0.086767</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.851664</td>\n",
       "      <td>0.217895</td>\n",
       "      <td>0.065668</td>\n",
       "      <td>0.023040</td>\n",
       "      <td>poisson</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>0.339303</td>\n",
       "      <td>0.501835</td>\n",
       "      <td>0.130604</td>\n",
       "      <td>0.323914</td>\n",
       "      <td>0.151945</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.471665</td>\n",
       "      <td>1.103077</td>\n",
       "      <td>0.183004</td>\n",
       "      <td>0.040006</td>\n",
       "      <td>poisson</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>0.351690</td>\n",
       "      <td>0.495069</td>\n",
       "      <td>0.153904</td>\n",
       "      <td>0.333554</td>\n",
       "      <td>0.139869</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.090995</td>\n",
       "      <td>0.132279</td>\n",
       "      <td>0.187670</td>\n",
       "      <td>0.062701</td>\n",
       "      <td>poisson</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>0.346333</td>\n",
       "      <td>0.508563</td>\n",
       "      <td>0.148598</td>\n",
       "      <td>0.334498</td>\n",
       "      <td>0.147193</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.576332</td>\n",
       "      <td>1.577241</td>\n",
       "      <td>0.431335</td>\n",
       "      <td>0.196302</td>\n",
       "      <td>poisson</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>0.342075</td>\n",
       "      <td>0.502576</td>\n",
       "      <td>0.163937</td>\n",
       "      <td>0.336196</td>\n",
       "      <td>0.138311</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8.214663</td>\n",
       "      <td>0.852004</td>\n",
       "      <td>0.495335</td>\n",
       "      <td>0.089496</td>\n",
       "      <td>poisson</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>0.343748</td>\n",
       "      <td>0.502274</td>\n",
       "      <td>0.157531</td>\n",
       "      <td>0.334518</td>\n",
       "      <td>0.140892</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.101998</td>\n",
       "      <td>0.138711</td>\n",
       "      <td>0.112668</td>\n",
       "      <td>0.016112</td>\n",
       "      <td>poisson</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 25, 'n_e...</td>\n",
       "      <td>0.732579</td>\n",
       "      <td>0.740665</td>\n",
       "      <td>0.541963</td>\n",
       "      <td>0.671736</td>\n",
       "      <td>0.091822</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.118333</td>\n",
       "      <td>0.472755</td>\n",
       "      <td>0.265336</td>\n",
       "      <td>0.097620</td>\n",
       "      <td>poisson</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 25, 'n_e...</td>\n",
       "      <td>0.717010</td>\n",
       "      <td>0.744700</td>\n",
       "      <td>0.534545</td>\n",
       "      <td>0.665418</td>\n",
       "      <td>0.093230</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7.735998</td>\n",
       "      <td>1.753279</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>0.127282</td>\n",
       "      <td>poisson</td>\n",
       "      <td>25</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 25, 'n_e...</td>\n",
       "      <td>0.720476</td>\n",
       "      <td>0.748738</td>\n",
       "      <td>0.533906</td>\n",
       "      <td>0.667707</td>\n",
       "      <td>0.095312</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5.417663</td>\n",
       "      <td>1.250192</td>\n",
       "      <td>0.181668</td>\n",
       "      <td>0.031416</td>\n",
       "      <td>poisson</td>\n",
       "      <td>25</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 25, 'n_e...</td>\n",
       "      <td>0.722285</td>\n",
       "      <td>0.747719</td>\n",
       "      <td>0.536729</td>\n",
       "      <td>0.668911</td>\n",
       "      <td>0.094042</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4.790003</td>\n",
       "      <td>0.070373</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>poisson</td>\n",
       "      <td>25</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 25, 'n_e...</td>\n",
       "      <td>0.727349</td>\n",
       "      <td>0.745123</td>\n",
       "      <td>0.536831</td>\n",
       "      <td>0.669768</td>\n",
       "      <td>0.094280</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.230996</td>\n",
       "      <td>0.072720</td>\n",
       "      <td>0.072669</td>\n",
       "      <td>0.031478</td>\n",
       "      <td>poisson</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 45, 'n_e...</td>\n",
       "      <td>0.739085</td>\n",
       "      <td>0.754934</td>\n",
       "      <td>0.577308</td>\n",
       "      <td>0.690442</td>\n",
       "      <td>0.080259</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2.299663</td>\n",
       "      <td>0.070240</td>\n",
       "      <td>0.096337</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>poisson</td>\n",
       "      <td>45</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 45, 'n_e...</td>\n",
       "      <td>0.737538</td>\n",
       "      <td>0.755459</td>\n",
       "      <td>0.574725</td>\n",
       "      <td>0.689240</td>\n",
       "      <td>0.081305</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3.525665</td>\n",
       "      <td>0.069326</td>\n",
       "      <td>0.159667</td>\n",
       "      <td>0.021637</td>\n",
       "      <td>poisson</td>\n",
       "      <td>45</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 45, 'n_e...</td>\n",
       "      <td>0.737293</td>\n",
       "      <td>0.756384</td>\n",
       "      <td>0.573594</td>\n",
       "      <td>0.689090</td>\n",
       "      <td>0.082039</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4.602332</td>\n",
       "      <td>0.178409</td>\n",
       "      <td>0.187001</td>\n",
       "      <td>0.004549</td>\n",
       "      <td>poisson</td>\n",
       "      <td>45</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 45, 'n_e...</td>\n",
       "      <td>0.742540</td>\n",
       "      <td>0.755402</td>\n",
       "      <td>0.575745</td>\n",
       "      <td>0.691229</td>\n",
       "      <td>0.081828</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.633333</td>\n",
       "      <td>0.182429</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.045701</td>\n",
       "      <td>poisson</td>\n",
       "      <td>45</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 45, 'n_e...</td>\n",
       "      <td>0.747559</td>\n",
       "      <td>0.755971</td>\n",
       "      <td>0.577212</td>\n",
       "      <td>0.693581</td>\n",
       "      <td>0.082357</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.597999      0.066716         0.045001        0.003266   \n",
       "1        1.199332      0.042459         0.088334        0.004785   \n",
       "2        2.003331      0.124196         0.128336        0.011815   \n",
       "3        2.239998      0.061747         0.166669        0.030005   \n",
       "4        2.865997      0.114814         0.208668        0.008497   \n",
       "5        0.775999      0.047377         0.062001        0.018403   \n",
       "6        1.657330      0.044011         0.139336        0.027011   \n",
       "7        2.323998      0.085515         0.151334        0.004641   \n",
       "8        3.075998      0.073542         0.190999        0.013949   \n",
       "9        3.891667      0.006184         0.297000        0.084914   \n",
       "10       0.723665      0.093902         0.063669        0.001700   \n",
       "11       1.403996      0.055398         0.132004        0.030595   \n",
       "12       2.347330      0.094462         0.142334        0.006944   \n",
       "13       3.004330      0.058368         0.242001        0.033534   \n",
       "14       3.672999      0.078259         0.286002        0.056786   \n",
       "15       1.589333      0.107690         0.046000        0.001633   \n",
       "16       3.120330      0.086170         0.082666        0.006181   \n",
       "17       4.596330      0.055259         0.111336        0.008498   \n",
       "18       6.189996      0.079717         0.160666        0.009743   \n",
       "19       7.545000      0.135477         0.187000        0.019593   \n",
       "20       2.222995      0.101418         0.050001        0.004544   \n",
       "21       4.370332      0.129208         0.100334        0.002494   \n",
       "22       9.718998      1.376534         0.380668        0.095228   \n",
       "23      10.036998      0.777633         0.206668        0.026400   \n",
       "24      11.498999      0.798871         0.325002        0.075978   \n",
       "25       2.578665      0.247992         0.059001        0.011861   \n",
       "26       5.349664      0.333029         0.184339        0.008657   \n",
       "27      11.814331      2.342956         0.510667        0.263015   \n",
       "28      24.536663      0.166643         0.713334        0.084307   \n",
       "29      18.893997      3.770183         0.264002        0.024750   \n",
       "30       0.851664      0.217895         0.065668        0.023040   \n",
       "31       2.471665      1.103077         0.183004        0.040006   \n",
       "32       2.090995      0.132279         0.187670        0.062701   \n",
       "33       4.576332      1.577241         0.431335        0.196302   \n",
       "34       8.214663      0.852004         0.495335        0.089496   \n",
       "35       2.101998      0.138711         0.112668        0.016112   \n",
       "36       5.118333      0.472755         0.265336        0.097620   \n",
       "37       7.735998      1.753279         0.301000        0.127282   \n",
       "38       5.417663      1.250192         0.181668        0.031416   \n",
       "39       4.790003      0.070373         0.218000        0.007256   \n",
       "40       1.230996      0.072720         0.072669        0.031478   \n",
       "41       2.299663      0.070240         0.096337        0.003297   \n",
       "42       3.525665      0.069326         0.159667        0.021637   \n",
       "43       4.602332      0.178409         0.187001        0.004549   \n",
       "44       5.633333      0.182429         0.240000        0.045701   \n",
       "\n",
       "   param_criterion param_max_depth param_n_estimators  \\\n",
       "0    squared_error               5                100   \n",
       "1    squared_error               5                200   \n",
       "2    squared_error               5                300   \n",
       "3    squared_error               5                400   \n",
       "4    squared_error               5                500   \n",
       "5    squared_error              25                100   \n",
       "6    squared_error              25                200   \n",
       "7    squared_error              25                300   \n",
       "8    squared_error              25                400   \n",
       "9    squared_error              25                500   \n",
       "10   squared_error              45                100   \n",
       "11   squared_error              45                200   \n",
       "12   squared_error              45                300   \n",
       "13   squared_error              45                400   \n",
       "14   squared_error              45                500   \n",
       "15  absolute_error               5                100   \n",
       "16  absolute_error               5                200   \n",
       "17  absolute_error               5                300   \n",
       "18  absolute_error               5                400   \n",
       "19  absolute_error               5                500   \n",
       "20  absolute_error              25                100   \n",
       "21  absolute_error              25                200   \n",
       "22  absolute_error              25                300   \n",
       "23  absolute_error              25                400   \n",
       "24  absolute_error              25                500   \n",
       "25  absolute_error              45                100   \n",
       "26  absolute_error              45                200   \n",
       "27  absolute_error              45                300   \n",
       "28  absolute_error              45                400   \n",
       "29  absolute_error              45                500   \n",
       "30         poisson               5                100   \n",
       "31         poisson               5                200   \n",
       "32         poisson               5                300   \n",
       "33         poisson               5                400   \n",
       "34         poisson               5                500   \n",
       "35         poisson              25                100   \n",
       "36         poisson              25                200   \n",
       "37         poisson              25                300   \n",
       "38         poisson              25                400   \n",
       "39         poisson              25                500   \n",
       "40         poisson              45                100   \n",
       "41         poisson              45                200   \n",
       "42         poisson              45                300   \n",
       "43         poisson              45                400   \n",
       "44         poisson              45                500   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'criterion': 'squared_error', 'max_depth': 5,...           0.801477   \n",
       "1   {'criterion': 'squared_error', 'max_depth': 5,...           0.804023   \n",
       "2   {'criterion': 'squared_error', 'max_depth': 5,...           0.804233   \n",
       "3   {'criterion': 'squared_error', 'max_depth': 5,...           0.804081   \n",
       "4   {'criterion': 'squared_error', 'max_depth': 5,...           0.801061   \n",
       "5   {'criterion': 'squared_error', 'max_depth': 25...           0.760389   \n",
       "6   {'criterion': 'squared_error', 'max_depth': 25...           0.759118   \n",
       "7   {'criterion': 'squared_error', 'max_depth': 25...           0.752733   \n",
       "8   {'criterion': 'squared_error', 'max_depth': 25...           0.753784   \n",
       "9   {'criterion': 'squared_error', 'max_depth': 25...           0.758392   \n",
       "10  {'criterion': 'squared_error', 'max_depth': 45...           0.751193   \n",
       "11  {'criterion': 'squared_error', 'max_depth': 45...           0.750571   \n",
       "12  {'criterion': 'squared_error', 'max_depth': 45...           0.750861   \n",
       "13  {'criterion': 'squared_error', 'max_depth': 45...           0.753126   \n",
       "14  {'criterion': 'squared_error', 'max_depth': 45...           0.748951   \n",
       "15  {'criterion': 'absolute_error', 'max_depth': 5...           0.823251   \n",
       "16  {'criterion': 'absolute_error', 'max_depth': 5...           0.824188   \n",
       "17  {'criterion': 'absolute_error', 'max_depth': 5...           0.823810   \n",
       "18  {'criterion': 'absolute_error', 'max_depth': 5...           0.824286   \n",
       "19  {'criterion': 'absolute_error', 'max_depth': 5...           0.824991   \n",
       "20  {'criterion': 'absolute_error', 'max_depth': 2...           0.764010   \n",
       "21  {'criterion': 'absolute_error', 'max_depth': 2...           0.771178   \n",
       "22  {'criterion': 'absolute_error', 'max_depth': 2...           0.763317   \n",
       "23  {'criterion': 'absolute_error', 'max_depth': 2...           0.767483   \n",
       "24  {'criterion': 'absolute_error', 'max_depth': 2...           0.768633   \n",
       "25  {'criterion': 'absolute_error', 'max_depth': 4...           0.771107   \n",
       "26  {'criterion': 'absolute_error', 'max_depth': 4...           0.767592   \n",
       "27  {'criterion': 'absolute_error', 'max_depth': 4...           0.764764   \n",
       "28  {'criterion': 'absolute_error', 'max_depth': 4...           0.767133   \n",
       "29  {'criterion': 'absolute_error', 'max_depth': 4...           0.762796   \n",
       "30  {'criterion': 'poisson', 'max_depth': 5, 'n_es...           0.339303   \n",
       "31  {'criterion': 'poisson', 'max_depth': 5, 'n_es...           0.351690   \n",
       "32  {'criterion': 'poisson', 'max_depth': 5, 'n_es...           0.346333   \n",
       "33  {'criterion': 'poisson', 'max_depth': 5, 'n_es...           0.342075   \n",
       "34  {'criterion': 'poisson', 'max_depth': 5, 'n_es...           0.343748   \n",
       "35  {'criterion': 'poisson', 'max_depth': 25, 'n_e...           0.732579   \n",
       "36  {'criterion': 'poisson', 'max_depth': 25, 'n_e...           0.717010   \n",
       "37  {'criterion': 'poisson', 'max_depth': 25, 'n_e...           0.720476   \n",
       "38  {'criterion': 'poisson', 'max_depth': 25, 'n_e...           0.722285   \n",
       "39  {'criterion': 'poisson', 'max_depth': 25, 'n_e...           0.727349   \n",
       "40  {'criterion': 'poisson', 'max_depth': 45, 'n_e...           0.739085   \n",
       "41  {'criterion': 'poisson', 'max_depth': 45, 'n_e...           0.737538   \n",
       "42  {'criterion': 'poisson', 'max_depth': 45, 'n_e...           0.737293   \n",
       "43  {'criterion': 'poisson', 'max_depth': 45, 'n_e...           0.742540   \n",
       "44  {'criterion': 'poisson', 'max_depth': 45, 'n_e...           0.747559   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.768729           0.614334         0.728180        0.081604   \n",
       "1            0.768080           0.614281         0.728795        0.082292   \n",
       "2            0.767697           0.619911         0.730613        0.079687   \n",
       "3            0.766794           0.617244         0.729373        0.080735   \n",
       "4            0.767800           0.612671         0.727177        0.082099   \n",
       "5            0.754058           0.576831         0.697093        0.085077   \n",
       "6            0.753202           0.578857         0.697059        0.083616   \n",
       "7            0.753976           0.579094         0.695268        0.082149   \n",
       "8            0.752243           0.581820         0.695949        0.080704   \n",
       "9            0.755369           0.578589         0.697450        0.084057   \n",
       "10           0.752092           0.580875         0.694720        0.080502   \n",
       "11           0.755123           0.579620         0.695105        0.081681   \n",
       "12           0.753541           0.578325         0.694242        0.081973   \n",
       "13           0.755528           0.573438         0.694030        0.085278   \n",
       "14           0.753111           0.582351         0.694804        0.079535   \n",
       "15           0.767422           0.612055         0.734243        0.089356   \n",
       "16           0.767052           0.614568         0.735269        0.088479   \n",
       "17           0.766413           0.611563         0.733929        0.089643   \n",
       "18           0.767629           0.615251         0.735722        0.088270   \n",
       "19           0.767756           0.615117         0.735955        0.088583   \n",
       "20           0.758525           0.581797         0.701444        0.084632   \n",
       "21           0.758695           0.578657         0.702844        0.087961   \n",
       "22           0.760079           0.572470         0.698622        0.089213   \n",
       "23           0.757604           0.578968         0.701352        0.086632   \n",
       "24           0.758758           0.579286         0.702226        0.087025   \n",
       "25           0.757026           0.581916         0.703350        0.086059   \n",
       "26           0.759651           0.575471         0.700905        0.088754   \n",
       "27           0.760079           0.575481         0.700108        0.088145   \n",
       "28           0.759372           0.571456         0.699320        0.090469   \n",
       "29           0.759418           0.577069         0.699761        0.086767   \n",
       "30           0.501835           0.130604         0.323914        0.151945   \n",
       "31           0.495069           0.153904         0.333554        0.139869   \n",
       "32           0.508563           0.148598         0.334498        0.147193   \n",
       "33           0.502576           0.163937         0.336196        0.138311   \n",
       "34           0.502274           0.157531         0.334518        0.140892   \n",
       "35           0.740665           0.541963         0.671736        0.091822   \n",
       "36           0.744700           0.534545         0.665418        0.093230   \n",
       "37           0.748738           0.533906         0.667707        0.095312   \n",
       "38           0.747719           0.536729         0.668911        0.094042   \n",
       "39           0.745123           0.536831         0.669768        0.094280   \n",
       "40           0.754934           0.577308         0.690442        0.080259   \n",
       "41           0.755459           0.574725         0.689240        0.081305   \n",
       "42           0.756384           0.573594         0.689090        0.082039   \n",
       "43           0.755402           0.575745         0.691229        0.081828   \n",
       "44           0.755971           0.577212         0.693581        0.082357   \n",
       "\n",
       "    rank_test_score  \n",
       "0                 9  \n",
       "1                 8  \n",
       "2                 6  \n",
       "3                 7  \n",
       "4                10  \n",
       "5                22  \n",
       "6                23  \n",
       "7                25  \n",
       "8                24  \n",
       "9                21  \n",
       "10               28  \n",
       "11               26  \n",
       "12               29  \n",
       "13               30  \n",
       "14               27  \n",
       "15                4  \n",
       "16                3  \n",
       "17                5  \n",
       "18                2  \n",
       "19                1  \n",
       "20               14  \n",
       "21               12  \n",
       "22               20  \n",
       "23               15  \n",
       "24               13  \n",
       "25               11  \n",
       "26               16  \n",
       "27               17  \n",
       "28               19  \n",
       "29               18  \n",
       "30               45  \n",
       "31               44  \n",
       "32               43  \n",
       "33               41  \n",
       "34               42  \n",
       "35               36  \n",
       "36               40  \n",
       "37               39  \n",
       "38               38  \n",
       "39               37  \n",
       "40               33  \n",
       "41               34  \n",
       "42               35  \n",
       "43               32  \n",
       "44               31  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7.545000</td>\n",
       "      <td>0.135477</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.019593</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 5...</td>\n",
       "      <td>0.824991</td>\n",
       "      <td>0.767756</td>\n",
       "      <td>0.615117</td>\n",
       "      <td>0.735955</td>\n",
       "      <td>0.088583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.189996</td>\n",
       "      <td>0.079717</td>\n",
       "      <td>0.160666</td>\n",
       "      <td>0.009743</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 5...</td>\n",
       "      <td>0.824286</td>\n",
       "      <td>0.767629</td>\n",
       "      <td>0.615251</td>\n",
       "      <td>0.735722</td>\n",
       "      <td>0.088270</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.120330</td>\n",
       "      <td>0.086170</td>\n",
       "      <td>0.082666</td>\n",
       "      <td>0.006181</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 5...</td>\n",
       "      <td>0.824188</td>\n",
       "      <td>0.767052</td>\n",
       "      <td>0.614568</td>\n",
       "      <td>0.735269</td>\n",
       "      <td>0.088479</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.589333</td>\n",
       "      <td>0.107690</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 5...</td>\n",
       "      <td>0.823251</td>\n",
       "      <td>0.767422</td>\n",
       "      <td>0.612055</td>\n",
       "      <td>0.734243</td>\n",
       "      <td>0.089356</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.596330</td>\n",
       "      <td>0.055259</td>\n",
       "      <td>0.111336</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 5...</td>\n",
       "      <td>0.823810</td>\n",
       "      <td>0.766413</td>\n",
       "      <td>0.611563</td>\n",
       "      <td>0.733929</td>\n",
       "      <td>0.089643</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.003331</td>\n",
       "      <td>0.124196</td>\n",
       "      <td>0.128336</td>\n",
       "      <td>0.011815</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 5,...</td>\n",
       "      <td>0.804233</td>\n",
       "      <td>0.767697</td>\n",
       "      <td>0.619911</td>\n",
       "      <td>0.730613</td>\n",
       "      <td>0.079687</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.239998</td>\n",
       "      <td>0.061747</td>\n",
       "      <td>0.166669</td>\n",
       "      <td>0.030005</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 5,...</td>\n",
       "      <td>0.804081</td>\n",
       "      <td>0.766794</td>\n",
       "      <td>0.617244</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>0.080735</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.199332</td>\n",
       "      <td>0.042459</td>\n",
       "      <td>0.088334</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 5,...</td>\n",
       "      <td>0.804023</td>\n",
       "      <td>0.768080</td>\n",
       "      <td>0.614281</td>\n",
       "      <td>0.728795</td>\n",
       "      <td>0.082292</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.597999</td>\n",
       "      <td>0.066716</td>\n",
       "      <td>0.045001</td>\n",
       "      <td>0.003266</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 5,...</td>\n",
       "      <td>0.801477</td>\n",
       "      <td>0.768729</td>\n",
       "      <td>0.614334</td>\n",
       "      <td>0.728180</td>\n",
       "      <td>0.081604</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.865997</td>\n",
       "      <td>0.114814</td>\n",
       "      <td>0.208668</td>\n",
       "      <td>0.008497</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 5,...</td>\n",
       "      <td>0.801061</td>\n",
       "      <td>0.767800</td>\n",
       "      <td>0.612671</td>\n",
       "      <td>0.727177</td>\n",
       "      <td>0.082099</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.578665</td>\n",
       "      <td>0.247992</td>\n",
       "      <td>0.059001</td>\n",
       "      <td>0.011861</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 4...</td>\n",
       "      <td>0.771107</td>\n",
       "      <td>0.757026</td>\n",
       "      <td>0.581916</td>\n",
       "      <td>0.703350</td>\n",
       "      <td>0.086059</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.370332</td>\n",
       "      <td>0.129208</td>\n",
       "      <td>0.100334</td>\n",
       "      <td>0.002494</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 2...</td>\n",
       "      <td>0.771178</td>\n",
       "      <td>0.758695</td>\n",
       "      <td>0.578657</td>\n",
       "      <td>0.702844</td>\n",
       "      <td>0.087961</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11.498999</td>\n",
       "      <td>0.798871</td>\n",
       "      <td>0.325002</td>\n",
       "      <td>0.075978</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>25</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 2...</td>\n",
       "      <td>0.768633</td>\n",
       "      <td>0.758758</td>\n",
       "      <td>0.579286</td>\n",
       "      <td>0.702226</td>\n",
       "      <td>0.087025</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.222995</td>\n",
       "      <td>0.101418</td>\n",
       "      <td>0.050001</td>\n",
       "      <td>0.004544</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 2...</td>\n",
       "      <td>0.764010</td>\n",
       "      <td>0.758525</td>\n",
       "      <td>0.581797</td>\n",
       "      <td>0.701444</td>\n",
       "      <td>0.084632</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10.036998</td>\n",
       "      <td>0.777633</td>\n",
       "      <td>0.206668</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>25</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 2...</td>\n",
       "      <td>0.767483</td>\n",
       "      <td>0.757604</td>\n",
       "      <td>0.578968</td>\n",
       "      <td>0.701352</td>\n",
       "      <td>0.086632</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.349664</td>\n",
       "      <td>0.333029</td>\n",
       "      <td>0.184339</td>\n",
       "      <td>0.008657</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>45</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 4...</td>\n",
       "      <td>0.767592</td>\n",
       "      <td>0.759651</td>\n",
       "      <td>0.575471</td>\n",
       "      <td>0.700905</td>\n",
       "      <td>0.088754</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>11.814331</td>\n",
       "      <td>2.342956</td>\n",
       "      <td>0.510667</td>\n",
       "      <td>0.263015</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>45</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 4...</td>\n",
       "      <td>0.764764</td>\n",
       "      <td>0.760079</td>\n",
       "      <td>0.575481</td>\n",
       "      <td>0.700108</td>\n",
       "      <td>0.088145</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>18.893997</td>\n",
       "      <td>3.770183</td>\n",
       "      <td>0.264002</td>\n",
       "      <td>0.024750</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>45</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 4...</td>\n",
       "      <td>0.762796</td>\n",
       "      <td>0.759418</td>\n",
       "      <td>0.577069</td>\n",
       "      <td>0.699761</td>\n",
       "      <td>0.086767</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>24.536663</td>\n",
       "      <td>0.166643</td>\n",
       "      <td>0.713334</td>\n",
       "      <td>0.084307</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>45</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 4...</td>\n",
       "      <td>0.767133</td>\n",
       "      <td>0.759372</td>\n",
       "      <td>0.571456</td>\n",
       "      <td>0.699320</td>\n",
       "      <td>0.090469</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>9.718998</td>\n",
       "      <td>1.376534</td>\n",
       "      <td>0.380668</td>\n",
       "      <td>0.095228</td>\n",
       "      <td>absolute_error</td>\n",
       "      <td>25</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'absolute_error', 'max_depth': 2...</td>\n",
       "      <td>0.763317</td>\n",
       "      <td>0.760079</td>\n",
       "      <td>0.572470</td>\n",
       "      <td>0.698622</td>\n",
       "      <td>0.089213</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.891667</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.297000</td>\n",
       "      <td>0.084914</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>25</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 25...</td>\n",
       "      <td>0.758392</td>\n",
       "      <td>0.755369</td>\n",
       "      <td>0.578589</td>\n",
       "      <td>0.697450</td>\n",
       "      <td>0.084057</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.775999</td>\n",
       "      <td>0.047377</td>\n",
       "      <td>0.062001</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 25...</td>\n",
       "      <td>0.760389</td>\n",
       "      <td>0.754058</td>\n",
       "      <td>0.576831</td>\n",
       "      <td>0.697093</td>\n",
       "      <td>0.085077</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.657330</td>\n",
       "      <td>0.044011</td>\n",
       "      <td>0.139336</td>\n",
       "      <td>0.027011</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 25...</td>\n",
       "      <td>0.759118</td>\n",
       "      <td>0.753202</td>\n",
       "      <td>0.578857</td>\n",
       "      <td>0.697059</td>\n",
       "      <td>0.083616</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.075998</td>\n",
       "      <td>0.073542</td>\n",
       "      <td>0.190999</td>\n",
       "      <td>0.013949</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>25</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 25...</td>\n",
       "      <td>0.753784</td>\n",
       "      <td>0.752243</td>\n",
       "      <td>0.581820</td>\n",
       "      <td>0.695949</td>\n",
       "      <td>0.080704</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.323998</td>\n",
       "      <td>0.085515</td>\n",
       "      <td>0.151334</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>25</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 25...</td>\n",
       "      <td>0.752733</td>\n",
       "      <td>0.753976</td>\n",
       "      <td>0.579094</td>\n",
       "      <td>0.695268</td>\n",
       "      <td>0.082149</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.403996</td>\n",
       "      <td>0.055398</td>\n",
       "      <td>0.132004</td>\n",
       "      <td>0.030595</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>45</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 45...</td>\n",
       "      <td>0.750571</td>\n",
       "      <td>0.755123</td>\n",
       "      <td>0.579620</td>\n",
       "      <td>0.695105</td>\n",
       "      <td>0.081681</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.672999</td>\n",
       "      <td>0.078259</td>\n",
       "      <td>0.286002</td>\n",
       "      <td>0.056786</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>45</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 45...</td>\n",
       "      <td>0.748951</td>\n",
       "      <td>0.753111</td>\n",
       "      <td>0.582351</td>\n",
       "      <td>0.694804</td>\n",
       "      <td>0.079535</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.723665</td>\n",
       "      <td>0.093902</td>\n",
       "      <td>0.063669</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 45...</td>\n",
       "      <td>0.751193</td>\n",
       "      <td>0.752092</td>\n",
       "      <td>0.580875</td>\n",
       "      <td>0.694720</td>\n",
       "      <td>0.080502</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.347330</td>\n",
       "      <td>0.094462</td>\n",
       "      <td>0.142334</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>45</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 45...</td>\n",
       "      <td>0.750861</td>\n",
       "      <td>0.753541</td>\n",
       "      <td>0.578325</td>\n",
       "      <td>0.694242</td>\n",
       "      <td>0.081973</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.004330</td>\n",
       "      <td>0.058368</td>\n",
       "      <td>0.242001</td>\n",
       "      <td>0.033534</td>\n",
       "      <td>squared_error</td>\n",
       "      <td>45</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'squared_error', 'max_depth': 45...</td>\n",
       "      <td>0.753126</td>\n",
       "      <td>0.755528</td>\n",
       "      <td>0.573438</td>\n",
       "      <td>0.694030</td>\n",
       "      <td>0.085278</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.633333</td>\n",
       "      <td>0.182429</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.045701</td>\n",
       "      <td>poisson</td>\n",
       "      <td>45</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 45, 'n_e...</td>\n",
       "      <td>0.747559</td>\n",
       "      <td>0.755971</td>\n",
       "      <td>0.577212</td>\n",
       "      <td>0.693581</td>\n",
       "      <td>0.082357</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>4.602332</td>\n",
       "      <td>0.178409</td>\n",
       "      <td>0.187001</td>\n",
       "      <td>0.004549</td>\n",
       "      <td>poisson</td>\n",
       "      <td>45</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 45, 'n_e...</td>\n",
       "      <td>0.742540</td>\n",
       "      <td>0.755402</td>\n",
       "      <td>0.575745</td>\n",
       "      <td>0.691229</td>\n",
       "      <td>0.081828</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.230996</td>\n",
       "      <td>0.072720</td>\n",
       "      <td>0.072669</td>\n",
       "      <td>0.031478</td>\n",
       "      <td>poisson</td>\n",
       "      <td>45</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 45, 'n_e...</td>\n",
       "      <td>0.739085</td>\n",
       "      <td>0.754934</td>\n",
       "      <td>0.577308</td>\n",
       "      <td>0.690442</td>\n",
       "      <td>0.080259</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2.299663</td>\n",
       "      <td>0.070240</td>\n",
       "      <td>0.096337</td>\n",
       "      <td>0.003297</td>\n",
       "      <td>poisson</td>\n",
       "      <td>45</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 45, 'n_e...</td>\n",
       "      <td>0.737538</td>\n",
       "      <td>0.755459</td>\n",
       "      <td>0.574725</td>\n",
       "      <td>0.689240</td>\n",
       "      <td>0.081305</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>3.525665</td>\n",
       "      <td>0.069326</td>\n",
       "      <td>0.159667</td>\n",
       "      <td>0.021637</td>\n",
       "      <td>poisson</td>\n",
       "      <td>45</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 45, 'n_e...</td>\n",
       "      <td>0.737293</td>\n",
       "      <td>0.756384</td>\n",
       "      <td>0.573594</td>\n",
       "      <td>0.689090</td>\n",
       "      <td>0.082039</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2.101998</td>\n",
       "      <td>0.138711</td>\n",
       "      <td>0.112668</td>\n",
       "      <td>0.016112</td>\n",
       "      <td>poisson</td>\n",
       "      <td>25</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 25, 'n_e...</td>\n",
       "      <td>0.732579</td>\n",
       "      <td>0.740665</td>\n",
       "      <td>0.541963</td>\n",
       "      <td>0.671736</td>\n",
       "      <td>0.091822</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4.790003</td>\n",
       "      <td>0.070373</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>poisson</td>\n",
       "      <td>25</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 25, 'n_e...</td>\n",
       "      <td>0.727349</td>\n",
       "      <td>0.745123</td>\n",
       "      <td>0.536831</td>\n",
       "      <td>0.669768</td>\n",
       "      <td>0.094280</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5.417663</td>\n",
       "      <td>1.250192</td>\n",
       "      <td>0.181668</td>\n",
       "      <td>0.031416</td>\n",
       "      <td>poisson</td>\n",
       "      <td>25</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 25, 'n_e...</td>\n",
       "      <td>0.722285</td>\n",
       "      <td>0.747719</td>\n",
       "      <td>0.536729</td>\n",
       "      <td>0.668911</td>\n",
       "      <td>0.094042</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>7.735998</td>\n",
       "      <td>1.753279</td>\n",
       "      <td>0.301000</td>\n",
       "      <td>0.127282</td>\n",
       "      <td>poisson</td>\n",
       "      <td>25</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 25, 'n_e...</td>\n",
       "      <td>0.720476</td>\n",
       "      <td>0.748738</td>\n",
       "      <td>0.533906</td>\n",
       "      <td>0.667707</td>\n",
       "      <td>0.095312</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.118333</td>\n",
       "      <td>0.472755</td>\n",
       "      <td>0.265336</td>\n",
       "      <td>0.097620</td>\n",
       "      <td>poisson</td>\n",
       "      <td>25</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 25, 'n_e...</td>\n",
       "      <td>0.717010</td>\n",
       "      <td>0.744700</td>\n",
       "      <td>0.534545</td>\n",
       "      <td>0.665418</td>\n",
       "      <td>0.093230</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.576332</td>\n",
       "      <td>1.577241</td>\n",
       "      <td>0.431335</td>\n",
       "      <td>0.196302</td>\n",
       "      <td>poisson</td>\n",
       "      <td>5</td>\n",
       "      <td>400</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>0.342075</td>\n",
       "      <td>0.502576</td>\n",
       "      <td>0.163937</td>\n",
       "      <td>0.336196</td>\n",
       "      <td>0.138311</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>8.214663</td>\n",
       "      <td>0.852004</td>\n",
       "      <td>0.495335</td>\n",
       "      <td>0.089496</td>\n",
       "      <td>poisson</td>\n",
       "      <td>5</td>\n",
       "      <td>500</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>0.343748</td>\n",
       "      <td>0.502274</td>\n",
       "      <td>0.157531</td>\n",
       "      <td>0.334518</td>\n",
       "      <td>0.140892</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2.090995</td>\n",
       "      <td>0.132279</td>\n",
       "      <td>0.187670</td>\n",
       "      <td>0.062701</td>\n",
       "      <td>poisson</td>\n",
       "      <td>5</td>\n",
       "      <td>300</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>0.346333</td>\n",
       "      <td>0.508563</td>\n",
       "      <td>0.148598</td>\n",
       "      <td>0.334498</td>\n",
       "      <td>0.147193</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2.471665</td>\n",
       "      <td>1.103077</td>\n",
       "      <td>0.183004</td>\n",
       "      <td>0.040006</td>\n",
       "      <td>poisson</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>0.351690</td>\n",
       "      <td>0.495069</td>\n",
       "      <td>0.153904</td>\n",
       "      <td>0.333554</td>\n",
       "      <td>0.139869</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.851664</td>\n",
       "      <td>0.217895</td>\n",
       "      <td>0.065668</td>\n",
       "      <td>0.023040</td>\n",
       "      <td>poisson</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>{'criterion': 'poisson', 'max_depth': 5, 'n_es...</td>\n",
       "      <td>0.339303</td>\n",
       "      <td>0.501835</td>\n",
       "      <td>0.130604</td>\n",
       "      <td>0.323914</td>\n",
       "      <td>0.151945</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "19       7.545000      0.135477         0.187000        0.019593   \n",
       "18       6.189996      0.079717         0.160666        0.009743   \n",
       "16       3.120330      0.086170         0.082666        0.006181   \n",
       "15       1.589333      0.107690         0.046000        0.001633   \n",
       "17       4.596330      0.055259         0.111336        0.008498   \n",
       "2        2.003331      0.124196         0.128336        0.011815   \n",
       "3        2.239998      0.061747         0.166669        0.030005   \n",
       "1        1.199332      0.042459         0.088334        0.004785   \n",
       "0        0.597999      0.066716         0.045001        0.003266   \n",
       "4        2.865997      0.114814         0.208668        0.008497   \n",
       "25       2.578665      0.247992         0.059001        0.011861   \n",
       "21       4.370332      0.129208         0.100334        0.002494   \n",
       "24      11.498999      0.798871         0.325002        0.075978   \n",
       "20       2.222995      0.101418         0.050001        0.004544   \n",
       "23      10.036998      0.777633         0.206668        0.026400   \n",
       "26       5.349664      0.333029         0.184339        0.008657   \n",
       "27      11.814331      2.342956         0.510667        0.263015   \n",
       "29      18.893997      3.770183         0.264002        0.024750   \n",
       "28      24.536663      0.166643         0.713334        0.084307   \n",
       "22       9.718998      1.376534         0.380668        0.095228   \n",
       "9        3.891667      0.006184         0.297000        0.084914   \n",
       "5        0.775999      0.047377         0.062001        0.018403   \n",
       "6        1.657330      0.044011         0.139336        0.027011   \n",
       "8        3.075998      0.073542         0.190999        0.013949   \n",
       "7        2.323998      0.085515         0.151334        0.004641   \n",
       "11       1.403996      0.055398         0.132004        0.030595   \n",
       "14       3.672999      0.078259         0.286002        0.056786   \n",
       "10       0.723665      0.093902         0.063669        0.001700   \n",
       "12       2.347330      0.094462         0.142334        0.006944   \n",
       "13       3.004330      0.058368         0.242001        0.033534   \n",
       "44       5.633333      0.182429         0.240000        0.045701   \n",
       "43       4.602332      0.178409         0.187001        0.004549   \n",
       "40       1.230996      0.072720         0.072669        0.031478   \n",
       "41       2.299663      0.070240         0.096337        0.003297   \n",
       "42       3.525665      0.069326         0.159667        0.021637   \n",
       "35       2.101998      0.138711         0.112668        0.016112   \n",
       "39       4.790003      0.070373         0.218000        0.007256   \n",
       "38       5.417663      1.250192         0.181668        0.031416   \n",
       "37       7.735998      1.753279         0.301000        0.127282   \n",
       "36       5.118333      0.472755         0.265336        0.097620   \n",
       "33       4.576332      1.577241         0.431335        0.196302   \n",
       "34       8.214663      0.852004         0.495335        0.089496   \n",
       "32       2.090995      0.132279         0.187670        0.062701   \n",
       "31       2.471665      1.103077         0.183004        0.040006   \n",
       "30       0.851664      0.217895         0.065668        0.023040   \n",
       "\n",
       "   param_criterion param_max_depth param_n_estimators  \\\n",
       "19  absolute_error               5                500   \n",
       "18  absolute_error               5                400   \n",
       "16  absolute_error               5                200   \n",
       "15  absolute_error               5                100   \n",
       "17  absolute_error               5                300   \n",
       "2    squared_error               5                300   \n",
       "3    squared_error               5                400   \n",
       "1    squared_error               5                200   \n",
       "0    squared_error               5                100   \n",
       "4    squared_error               5                500   \n",
       "25  absolute_error              45                100   \n",
       "21  absolute_error              25                200   \n",
       "24  absolute_error              25                500   \n",
       "20  absolute_error              25                100   \n",
       "23  absolute_error              25                400   \n",
       "26  absolute_error              45                200   \n",
       "27  absolute_error              45                300   \n",
       "29  absolute_error              45                500   \n",
       "28  absolute_error              45                400   \n",
       "22  absolute_error              25                300   \n",
       "9    squared_error              25                500   \n",
       "5    squared_error              25                100   \n",
       "6    squared_error              25                200   \n",
       "8    squared_error              25                400   \n",
       "7    squared_error              25                300   \n",
       "11   squared_error              45                200   \n",
       "14   squared_error              45                500   \n",
       "10   squared_error              45                100   \n",
       "12   squared_error              45                300   \n",
       "13   squared_error              45                400   \n",
       "44         poisson              45                500   \n",
       "43         poisson              45                400   \n",
       "40         poisson              45                100   \n",
       "41         poisson              45                200   \n",
       "42         poisson              45                300   \n",
       "35         poisson              25                100   \n",
       "39         poisson              25                500   \n",
       "38         poisson              25                400   \n",
       "37         poisson              25                300   \n",
       "36         poisson              25                200   \n",
       "33         poisson               5                400   \n",
       "34         poisson               5                500   \n",
       "32         poisson               5                300   \n",
       "31         poisson               5                200   \n",
       "30         poisson               5                100   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "19  {'criterion': 'absolute_error', 'max_depth': 5...           0.824991   \n",
       "18  {'criterion': 'absolute_error', 'max_depth': 5...           0.824286   \n",
       "16  {'criterion': 'absolute_error', 'max_depth': 5...           0.824188   \n",
       "15  {'criterion': 'absolute_error', 'max_depth': 5...           0.823251   \n",
       "17  {'criterion': 'absolute_error', 'max_depth': 5...           0.823810   \n",
       "2   {'criterion': 'squared_error', 'max_depth': 5,...           0.804233   \n",
       "3   {'criterion': 'squared_error', 'max_depth': 5,...           0.804081   \n",
       "1   {'criterion': 'squared_error', 'max_depth': 5,...           0.804023   \n",
       "0   {'criterion': 'squared_error', 'max_depth': 5,...           0.801477   \n",
       "4   {'criterion': 'squared_error', 'max_depth': 5,...           0.801061   \n",
       "25  {'criterion': 'absolute_error', 'max_depth': 4...           0.771107   \n",
       "21  {'criterion': 'absolute_error', 'max_depth': 2...           0.771178   \n",
       "24  {'criterion': 'absolute_error', 'max_depth': 2...           0.768633   \n",
       "20  {'criterion': 'absolute_error', 'max_depth': 2...           0.764010   \n",
       "23  {'criterion': 'absolute_error', 'max_depth': 2...           0.767483   \n",
       "26  {'criterion': 'absolute_error', 'max_depth': 4...           0.767592   \n",
       "27  {'criterion': 'absolute_error', 'max_depth': 4...           0.764764   \n",
       "29  {'criterion': 'absolute_error', 'max_depth': 4...           0.762796   \n",
       "28  {'criterion': 'absolute_error', 'max_depth': 4...           0.767133   \n",
       "22  {'criterion': 'absolute_error', 'max_depth': 2...           0.763317   \n",
       "9   {'criterion': 'squared_error', 'max_depth': 25...           0.758392   \n",
       "5   {'criterion': 'squared_error', 'max_depth': 25...           0.760389   \n",
       "6   {'criterion': 'squared_error', 'max_depth': 25...           0.759118   \n",
       "8   {'criterion': 'squared_error', 'max_depth': 25...           0.753784   \n",
       "7   {'criterion': 'squared_error', 'max_depth': 25...           0.752733   \n",
       "11  {'criterion': 'squared_error', 'max_depth': 45...           0.750571   \n",
       "14  {'criterion': 'squared_error', 'max_depth': 45...           0.748951   \n",
       "10  {'criterion': 'squared_error', 'max_depth': 45...           0.751193   \n",
       "12  {'criterion': 'squared_error', 'max_depth': 45...           0.750861   \n",
       "13  {'criterion': 'squared_error', 'max_depth': 45...           0.753126   \n",
       "44  {'criterion': 'poisson', 'max_depth': 45, 'n_e...           0.747559   \n",
       "43  {'criterion': 'poisson', 'max_depth': 45, 'n_e...           0.742540   \n",
       "40  {'criterion': 'poisson', 'max_depth': 45, 'n_e...           0.739085   \n",
       "41  {'criterion': 'poisson', 'max_depth': 45, 'n_e...           0.737538   \n",
       "42  {'criterion': 'poisson', 'max_depth': 45, 'n_e...           0.737293   \n",
       "35  {'criterion': 'poisson', 'max_depth': 25, 'n_e...           0.732579   \n",
       "39  {'criterion': 'poisson', 'max_depth': 25, 'n_e...           0.727349   \n",
       "38  {'criterion': 'poisson', 'max_depth': 25, 'n_e...           0.722285   \n",
       "37  {'criterion': 'poisson', 'max_depth': 25, 'n_e...           0.720476   \n",
       "36  {'criterion': 'poisson', 'max_depth': 25, 'n_e...           0.717010   \n",
       "33  {'criterion': 'poisson', 'max_depth': 5, 'n_es...           0.342075   \n",
       "34  {'criterion': 'poisson', 'max_depth': 5, 'n_es...           0.343748   \n",
       "32  {'criterion': 'poisson', 'max_depth': 5, 'n_es...           0.346333   \n",
       "31  {'criterion': 'poisson', 'max_depth': 5, 'n_es...           0.351690   \n",
       "30  {'criterion': 'poisson', 'max_depth': 5, 'n_es...           0.339303   \n",
       "\n",
       "    split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "19           0.767756           0.615117         0.735955        0.088583   \n",
       "18           0.767629           0.615251         0.735722        0.088270   \n",
       "16           0.767052           0.614568         0.735269        0.088479   \n",
       "15           0.767422           0.612055         0.734243        0.089356   \n",
       "17           0.766413           0.611563         0.733929        0.089643   \n",
       "2            0.767697           0.619911         0.730613        0.079687   \n",
       "3            0.766794           0.617244         0.729373        0.080735   \n",
       "1            0.768080           0.614281         0.728795        0.082292   \n",
       "0            0.768729           0.614334         0.728180        0.081604   \n",
       "4            0.767800           0.612671         0.727177        0.082099   \n",
       "25           0.757026           0.581916         0.703350        0.086059   \n",
       "21           0.758695           0.578657         0.702844        0.087961   \n",
       "24           0.758758           0.579286         0.702226        0.087025   \n",
       "20           0.758525           0.581797         0.701444        0.084632   \n",
       "23           0.757604           0.578968         0.701352        0.086632   \n",
       "26           0.759651           0.575471         0.700905        0.088754   \n",
       "27           0.760079           0.575481         0.700108        0.088145   \n",
       "29           0.759418           0.577069         0.699761        0.086767   \n",
       "28           0.759372           0.571456         0.699320        0.090469   \n",
       "22           0.760079           0.572470         0.698622        0.089213   \n",
       "9            0.755369           0.578589         0.697450        0.084057   \n",
       "5            0.754058           0.576831         0.697093        0.085077   \n",
       "6            0.753202           0.578857         0.697059        0.083616   \n",
       "8            0.752243           0.581820         0.695949        0.080704   \n",
       "7            0.753976           0.579094         0.695268        0.082149   \n",
       "11           0.755123           0.579620         0.695105        0.081681   \n",
       "14           0.753111           0.582351         0.694804        0.079535   \n",
       "10           0.752092           0.580875         0.694720        0.080502   \n",
       "12           0.753541           0.578325         0.694242        0.081973   \n",
       "13           0.755528           0.573438         0.694030        0.085278   \n",
       "44           0.755971           0.577212         0.693581        0.082357   \n",
       "43           0.755402           0.575745         0.691229        0.081828   \n",
       "40           0.754934           0.577308         0.690442        0.080259   \n",
       "41           0.755459           0.574725         0.689240        0.081305   \n",
       "42           0.756384           0.573594         0.689090        0.082039   \n",
       "35           0.740665           0.541963         0.671736        0.091822   \n",
       "39           0.745123           0.536831         0.669768        0.094280   \n",
       "38           0.747719           0.536729         0.668911        0.094042   \n",
       "37           0.748738           0.533906         0.667707        0.095312   \n",
       "36           0.744700           0.534545         0.665418        0.093230   \n",
       "33           0.502576           0.163937         0.336196        0.138311   \n",
       "34           0.502274           0.157531         0.334518        0.140892   \n",
       "32           0.508563           0.148598         0.334498        0.147193   \n",
       "31           0.495069           0.153904         0.333554        0.139869   \n",
       "30           0.501835           0.130604         0.323914        0.151945   \n",
       "\n",
       "    rank_test_score  \n",
       "19                1  \n",
       "18                2  \n",
       "16                3  \n",
       "15                4  \n",
       "17                5  \n",
       "2                 6  \n",
       "3                 7  \n",
       "1                 8  \n",
       "0                 9  \n",
       "4                10  \n",
       "25               11  \n",
       "21               12  \n",
       "24               13  \n",
       "20               14  \n",
       "23               15  \n",
       "26               16  \n",
       "27               17  \n",
       "29               18  \n",
       "28               19  \n",
       "22               20  \n",
       "9                21  \n",
       "5                22  \n",
       "6                23  \n",
       "8                24  \n",
       "7                25  \n",
       "11               26  \n",
       "14               27  \n",
       "10               28  \n",
       "12               29  \n",
       "13               30  \n",
       "44               31  \n",
       "43               32  \n",
       "40               33  \n",
       "41               34  \n",
       "42               35  \n",
       "35               36  \n",
       "39               37  \n",
       "38               38  \n",
       "37               39  \n",
       "36               40  \n",
       "33               41  \n",
       "34               42  \n",
       "32               43  \n",
       "31               44  \n",
       "30               45  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gf.sort_values(by='rank_test_score',inplace=True)\n",
    "gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['house_pricing_model_73.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(grid.best_estimator_,\"house_pricing_model_73.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a29e1fb6683002b636560db254076994f59567f0270ab4cc0d58f0bc21ebc82f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
